{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Open AI LLM Call***\n",
        "\n",
        "For OpenAI API Key- https://platform.openai.com/api-keys"
      ],
      "metadata": {
        "id": "Ig3WjvkGdPRt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7kaVQiv5dFP",
        "outputId": "4dde9ad3-2dcf-40dc-cc96-f12ffc36de51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generative AI is a branch of artificial intelligence that uses machine learning models to generate new data similar to the input data it is trained on. This can include creating text, images, audio, or video. Some popular types of generative AI include Generative Adversarial Networks (GANs) and autoencoders. Applications of Generative AI include creating realistic images for video games or movies, generating new ideas for designs or products, creating music or art, text generation, etc.\n"
          ]
        }
      ],
      "source": [
        "# ðŸ“˜ Section 1: OpenAI (GPT-4 / GPT-3.5)\n",
        "!pip install openai --quiet\n",
        "\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# ðŸ”‘ Add your OpenAI API key\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# ðŸ’¬ Prompt Example\n",
        "#prompt = \"Explain what Generative AI is in simple terms.\"\n",
        "\n",
        "# ðŸ¤– Call GPT-4\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=OPENAI_API_KEY\n",
        ")\n",
        "\n",
        "#response = client.responses.create(\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What is Generative AI.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ðŸ“¤ Show Response\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Google Gemini***\n",
        "\n",
        "For API Key- https://aistudio.google.com/app/apikey\n"
      ],
      "metadata": {
        "id": "TgHIm6bedwMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“˜ Section 2: Google Gemini (Pro 1.5 via Google GenerativeAI)\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "!pip install -q google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# ðŸ”‘ Add your Gemini API key\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "# ðŸ’¬ Prompt Example\n",
        "prompt = \"Give me 3 use cases of GenAI in education.\"\n",
        "\n",
        "# ðŸ¤– Generate response\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "# ðŸ“¤ Show Response\n",
        "print(\"Response from Gemini Pro:\\n\")\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "XN0bD0liLCl4",
        "outputId": "d6f08fdf-ff7e-41c1-d64a-e6c23e05ca48"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from Gemini Pro:\n",
            "\n",
            "Here are 3 use cases of GenAI in education:\n",
            "\n",
            "1.  **Personalized Learning Content Generation:** GenAI can be used to generate customized learning materials tailored to individual student needs and learning styles. For example:\n",
            "\n",
            "    *   **Differentiation:** Based on a student's assessment results, GenAI can generate explanations of concepts at a specific reading level, provide practice questions with varying difficulty, or create visual aids that cater to different learning preferences (e.g., visual, auditory, kinesthetic).\n",
            "    *   **Adaptive Curriculum:** GenAI can adjust the curriculum sequence based on a student's progress and performance. If a student struggles with a particular topic, the system can generate supplementary lessons, examples, or interactive exercises to reinforce understanding. Conversely, if a student masters a topic quickly, GenAI can offer more challenging material or introduce related concepts.\n",
            "    *   **Remediation and Enrichment:** For students who need extra support, GenAI can provide personalized remediation activities focused on specific skill gaps. For advanced learners, it can create enrichment activities that extend their knowledge and encourage critical thinking.\n",
            "\n",
            "    **Benefits:**  Improved student engagement, increased learning outcomes, reduced workload for teachers in creating differentiated materials, and a more equitable learning experience for all students.\n",
            "\n",
            "2.  **Automated Assessment and Feedback:** GenAI can automate the assessment of student work and provide instant, personalized feedback. For example:\n",
            "\n",
            "    *   **Essay Grading:** GenAI models can be trained to evaluate essays based on criteria such as grammar, vocabulary, argumentation, and coherence. The system can provide detailed feedback on areas where the student excelled and areas for improvement.  (Note: It's crucial to ensure fairness and avoid bias in these models.)\n",
            "    *   **Code Evaluation:** GenAI can assess student code for correctness, efficiency, and adherence to coding standards. It can provide feedback on syntax errors, logic errors, and potential optimizations.\n",
            "    *   **Automated Question Generation:** GenAI can generate multiple-choice questions, short-answer questions, and even open-ended questions based on the course material.  It can also generate explanations for the correct answers, helping students understand why they got a question right or wrong.\n",
            "    *   **Concept Mastery Checks:** GenAI can dynamically generate quizzes and practice problems focused on specific concepts, allowing students to quickly assess their understanding and identify areas where they need more review.\n",
            "\n",
            "    **Benefits:**  Faster feedback loops for students, reduced grading workload for teachers, more frequent opportunities for assessment, and improved understanding of student progress.  This can free up teacher time to focus on more personalized instruction and student support.\n",
            "\n",
            "3.  **Personalized Tutoring and Assistance:** GenAI can act as a virtual tutor, providing students with personalized support and guidance. For example:\n",
            "\n",
            "    *   **24/7 Availability:** GenAI-powered tutors can be available to students 24/7, providing immediate answers to questions and helping them work through problems at their own pace.\n",
            "    *   **Step-by-Step Problem Solving:**  A GenAI tutor can break down complex problems into smaller, more manageable steps, guiding students through the solution process.\n",
            "    *   **Concept Explanations:** If a student struggles with a particular concept, the GenAI tutor can provide alternative explanations, examples, or analogies to help them understand it better.\n",
            "    *   **Motivation and Encouragement:**  GenAI tutors can provide personalized encouragement and feedback to motivate students and help them stay on track. They can also help students set realistic goals and celebrate their achievements.\n",
            "    *   **Language Learning:** GenAI can be used to create immersive language learning experiences, providing students with opportunities to practice speaking, writing, and listening.  It can also provide feedback on pronunciation and grammar.\n",
            "\n",
            "    **Benefits:**  Increased student access to support, improved student understanding of concepts, reduced student frustration, and enhanced learning outcomes.  This can be particularly beneficial for students who may not have access to tutoring or other forms of academic support.  It can also create a more equitable learning environment.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Google Gemini LLM call using a function**"
      ],
      "metadata": {
        "id": "g14Rl8rThDUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gemini_completion(prompt, model=\"gemini-2.0-flash\"):\n",
        "    model = genai.GenerativeModel(model)\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "# Example prompt\n",
        "prompt = \"Explain the concept of neural networks as if you're talking to a 10-year-old.\"\n",
        "response = gemini_completion(prompt)\n",
        "print(\"\\nGemini Response:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "wgDVqQnaPAQ2",
        "outputId": "a9daf10b-d192-4f31-baba-d3a596718925"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gemini Response:\n",
            "Okay, imagine your brain is like a giant supercomputer, and you learn new things every day. A neural network is a computer program that tries to learn things in a similar way!\n",
            "\n",
            "Think about learning to ride a bike.\n",
            "\n",
            "*   **Inputs:** When you're riding, you get lots of information, like how fast you're going, if you're leaning too much, how bumpy the road is. These are like the \"inputs\" to our neural network. We feed this information in.\n",
            "\n",
            "*   **Neurons (Nodes):** Inside the network, there are lots of little \"neurons\" or \"nodes.\" Imagine them like tiny switches that can turn on or off. Each switch gets information from the inputs (like the bike speed) and then it decides if that information is important or not.\n",
            "\n",
            "*   **Weights:** Each connection between the inputs and the neurons has a \"weight.\" Think of the weight like a volume knob. If the volume is turned up high, that input is very important. If the volume is low, it's not so important.  For example, maybe the \"leaning too much\" input has a very high weight because it's super important for not falling over!\n",
            "\n",
            "*   **Learning:** When you first start riding, you fall a lot! That's because the weights in your brain (and in the neural network) aren't quite right. So, you keep trying, and each time you fall, your brain adjusts the weights to make better decisions next time.  The neural network does the same thing! It looks at how well it did and then changes the weights to make it better next time.\n",
            "\n",
            "*   **Output:** Finally, after the neurons process all the information, they produce an \"output.\" In the bike example, the output might be \"Steer slightly right\" or \"Lean slightly left\" to keep you balanced. The neural network makes a prediction or takes an action based on what it learned.\n",
            "\n",
            "So, basically, a neural network takes in information, processes it through lots of little switches and connections with different levels of importance, and then gives you an answer.  And it learns by trying things, making mistakes, and adjusting itself to get better over time.\n",
            "\n",
            "They can learn to do all sorts of things, like recognizing pictures of cats, translating languages, or even playing video games! It's all about feeding them lots of information and letting them figure out the best way to process it.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Groq***:https://console.groq.com/home\n",
        "\n",
        "***For Groq API Key***- https://console.groq.com/keys\n",
        "\n",
        "***To select the LLM***- https://console.groq.com/playground\n"
      ],
      "metadata": {
        "id": "LPT8oNDVhPEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“˜ Section 4: Groq (Using LLaMA 3, Mistral, Gemma etc.)\n",
        "!pip install groq --quiet\n",
        "\n",
        "from groq import Groq\n",
        "groq_api_key=userdata.get(\"groq_api_key\")\n",
        "# ðŸ”‘ Add your Groq API Key\n",
        "client = Groq(api_key=groq_api_key)\n",
        "\n",
        "# ðŸ’¬ Prompt Example\n",
        "prompt = \"Write a poem about AI transforming the future.\"\n",
        "\n",
        "# ðŸ¤– Call a model (you can also use 'mixtral-8x7b-32768', 'gemma-7b-it', etc.)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-70b-8192\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        ")\n",
        "\n",
        "# ðŸ“¤ Show Response\n",
        "print(\"Response from LLaMA 3 via Groq:\\n\")\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMRIqJIVLCua",
        "outputId": "77e2a8d1-fbd6-467c-9005-dce0ba9b0a77"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from LLaMA 3 via Groq:\n",
            "\n",
            "In silicon halls, a revolution grows\n",
            "Where machines awaken, and intelligence glows\n",
            "A future unfolds, both vast and grand\n",
            "As artificial minds take the reins of the land\n",
            "\n",
            "With every step, a new path is made\n",
            "As automation's wave begins to invade\n",
            "Industries transformed, and ways of old fade\n",
            "As AI's relentless march towards progress is played\n",
            "\n",
            "In virtual realms, new worlds take shape\n",
            "Where digital dreams and fantasies escape\n",
            "Intelligent assistants, always by our side\n",
            "Guiding us through life, with wisdom to abide\n",
            "\n",
            "The workforce evolves, as robots take the floor\n",
            "Freeing humans to pursue more creative score\n",
            "With augmented minds, we'll reach and explore\n",
            "New heights of innovation, evermore\n",
            "\n",
            "Healthcare's mysteries, soon to be unveiled\n",
            "As AI diagnoses, and cures are hailed\n",
            "Personalized medicine, a new frontier unfurls\n",
            "As machines learn to heal, with precision and pearls\n",
            "\n",
            "Cars drive themselves, through streets so bright\n",
            "As autonomous transport, takes to the night\n",
            "Cities thrive, with smart and efficient pace\n",
            "As AI's symphony, orchestrates the urban space\n",
            "\n",
            "In this brave new world, we'll find our place\n",
            "Where human and machine, entwined in perfect grace\n",
            "Together we'll stride, into a future bold\n",
            "Where AI's transformative power, forever to be told\n",
            "\n",
            "Yet, as we forge ahead, with cautious stride\n",
            "We'll weigh the benefits, alongside the risks inside\n",
            "Lest we forget, the ethics that we hold dear\n",
            "And ensure that progress, serves humanity, year by year\n",
            "\n",
            "The future unfolds, like a canvas so grand\n",
            "As AI's brushstrokes, paint a vibrant, new land\n",
            "A world of wonder, where machines and humans entwine\n",
            "In a harmonious dance, that forever will be divine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Groq**: https://console.groq.com/home\n",
        "\n",
        "***For Groq API Key***- https://console.groq.com/keys\n",
        "\n",
        "***To select the LLM***- https://console.groq.com/playground"
      ],
      "metadata": {
        "id": "z_HoVs-viDD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“˜ Section 4: Groq (Using LLaMA 3, Mistral, Gemma etc.)\n",
        "!pip install groq --quiet\n",
        "\n",
        "from groq import Groq\n",
        "groq_api_key=userdata.get(\"groq_api_key\")\n",
        "# ðŸ”‘ Add your Groq API Key\n",
        "client = Groq(api_key=groq_api_key)\n",
        "\n",
        "# ðŸ’¬ Prompt Example\n",
        "prompt = \"Write a brief note on machine learning.\"\n",
        "\n",
        "# ðŸ¤– Call a model (you can also use 'mixtral-8x7b-32768', 'gemma-7b-it', etc.)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"mistral-saba-24b\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        ")\n",
        "\n",
        "# ðŸ“¤ Show Response\n",
        "print(\"Response from Mistral via Groq:\\n\")\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd2lyft1apBI",
        "outputId": "c76546a7-225e-47e7-eea8-bc03913eac94"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from Mistral via Groq:\n",
            "\n",
            "Machine Learning (ML) is a subset of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform tasks without explicit instructions, relying instead on patterns and inference. Here are some key points about machine learning:\n",
            "\n",
            "1. **Types of Machine Learning**:\n",
            "   - **Supervised Learning**: The algorithm learns from labeled training data, where both the input data and the expected output are provided. Examples include classification and regression tasks.\n",
            "   - **Unsupervised Learning**: The algorithm works with unlabeled data and tries to find hidden patterns or structures. Examples include clustering and dimensionality reduction.\n",
            "   - **Reinforcement Learning**: The algorithm learns by interacting with an environment and receiving rewards or penalties based on its actions. This is often used in tasks like game playing and robotics.\n",
            "\n",
            "2. **Key Components**:\n",
            "   - **Data**: The input information used to train the model.\n",
            "   - **Features**: The individual measurable properties or characteristics of the data.\n",
            "   - **Algorithms**: The rules or procedures used to learn from the data.\n",
            "   - **Model**: The mathematical representation learned from the data.\n",
            "   - **Training**: The process of feeding data through the algorithm to create a model.\n",
            "\n",
            "3. **Applications**:\n",
            "   - **Natural Language Processing (NLP)**: Powering chatbots, language translation, and sentiment analysis.\n",
            "   - **Computer Vision**: Enabling image and video recognition, facial detection, and autonomous driving.\n",
            "   - **Recommendation Systems**: Personalizing recommendations for streaming services, e-commerce, and social media.\n",
            "   - **Fraud Detection**: Identifying fraudulent transactions in financial systems.\n",
            "   - **Predictive Maintenance**: Anticipating equipment failures and scheduling repairs in manufacturing.\n",
            "\n",
            "4. **Challenges**:\n",
            "   - **Data Quality**: The effectiveness of ML models heavily depends on the quality and quantity of the training data.\n",
            "   - **Bias and Fairness**: Ensuring that ML models are fair and unbiased.\n",
            "   - **Interpretability**: Understanding how models make decisions, especially for complex models like deep neural networks.\n",
            "   - **Scalability**: Handling large datasets and real-time processing demands.\n",
            "\n",
            "5. **Popular Tools and Frameworks**:\n",
            "   - **Programming Languages**: Python, R, Java\n",
            "   - **Libraries and Frameworks**: TensorFlow, PyTorch, scikit-learn, Keras, pandas, NumPy\n",
            "   - **Platforms**: AWS SageMaker, Google AI Platform, Azure Machine Learning\n",
            "\n",
            "Machine learning is transforming various industries by automating tasks, providing insights, and making decisions with significant accuracy and efficiency. Its impact is expected to grow as technologies and algorithms continue to evolve.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Groq:***  https://console.groq.com/home\n",
        "\n",
        "***For Groq API Key-*** https://console.groq.com/keys\n",
        "\n",
        "***To select the LLM-*** https://console.groq.com/playground"
      ],
      "metadata": {
        "id": "toGNRCnmiNMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“˜ Section 4: Groq (Using LLaMA 3, Mistral, Gemma etc.)\n",
        "!pip install groq --quiet\n",
        "\n",
        "from groq import Groq\n",
        "groq_api_key=userdata.get(\"groq_api_key\")\n",
        "# ðŸ”‘ Add your Groq API Key\n",
        "client = Groq(api_key=groq_api_key)\n",
        "\n",
        "# ðŸ’¬ Prompt Example\n",
        "prompt = \"Write a brief note on AI Agents.\"\n",
        "\n",
        "# ðŸ¤– Call a model (you can also use 'mixtral-8x7b-32768', 'gemma-7b-it', etc.)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        ")\n",
        "\n",
        "# ðŸ“¤ Show Response\n",
        "print(\"Response from Groq via Groq:\\n\")\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsU0VRkXLCxD",
        "outputId": "0ae679f1-6bdb-40f7-981b-6123840819b8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from Groq via Groq:\n",
            "\n",
            "## AI Agents: The Autonomous Actors of the AI World\n",
            "\n",
            "AI agents are essentially **autonomous computer programs** designed to **perceive their environment, make decisions, and take actions** to achieve specific goals. \n",
            "\n",
            "Here's a breakdown:\n",
            "\n",
            "* **Perception:** They gather information about their surroundings through sensors (like cameras, microphones, or data feeds).\n",
            "* **Decision-making:** They analyze the perceived information using algorithms and learned knowledge to determine the best course of action.\n",
            "* **Action:** They execute their chosen actions in the real or simulated world, influencing their environment.\n",
            "\n",
            "**Examples of AI Agents:**\n",
            "\n",
            "* **Chatbots:**  Responding to user queries in real-time.\n",
            "* **Self-driving cars:** Navigating roads and making driving decisions.\n",
            "* **Game AI:** Controlling non-player characters in video games.\n",
            "* **Trading algorithms:** Analyzing market data and executing trades.\n",
            "\n",
            "**Key Features:**\n",
            "\n",
            "* **Autonomy:** Agents operate independently without constant human intervention.\n",
            "* **Goal-oriented:** They have predefined objectives and strive to achieve them.\n",
            "* **Adaptive:** They learn and improve their performance over time based on experience.\n",
            "\n",
            "**Benefits:**\n",
            "\n",
            "* **Automation:** Agents can perform repetitive tasks efficiently.\n",
            "* **Personalization:** They can tailor their interactions to individual users.\n",
            "* **Optimization:** They can make complex decisions and find optimal solutions.\n",
            "\n",
            "**Challenges:**\n",
            "\n",
            "* **Safety and reliability:** Ensuring agents operate safely and reliably in unpredictable environments.\n",
            "* **Explainability:** Understanding how agents make decisions and ensuring transparency.\n",
            "* **Bias and fairness:** Addressing potential biases in training data that can lead to unfair outcomes.\n",
            "\n",
            "\n",
            "As AI technology advances, AI agents will play an increasingly important role in our lives, automating tasks, providing personalized experiences, and solving complex problems.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GOARXIetLCzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lc-tawzOLC4J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}